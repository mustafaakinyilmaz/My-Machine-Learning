{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import skimage as sk\n",
    "\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, bias):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "    \n",
    "        self.height, self.width = input_size\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias        = bias\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "        \n",
    "        self.linear = nn.Linear(in_features=self.hidden_dim*self.height*self.width,out_features=1,bias=self.bias)\n",
    "        \n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        \n",
    "        if cur_state is None:\n",
    "            cur_state = (Variable(torch.zeros(1, self.hidden_dim, self.height, self.width)),\n",
    "                Variable(torch.zeros(1, self.hidden_dim, self.height, self.width)))\n",
    "        \n",
    "        h_cur, c_cur = cur_state\n",
    "        \n",
    "        #print(input_tensor.size(),h_cur.size())\n",
    "        combined = torch.cat((input_tensor, h_cur), dim=1)  # concatenate along channel axis\n",
    "        #print(combined.size())\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1) \n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        \n",
    "        next_state = (h_next,c_next)\n",
    "        \n",
    "        sigmoid_out = F.sigmoid(self.linear(h_next.view(1,-1)))\n",
    "        \n",
    "        return next_state,sigmoid_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c, h, w = 5, 4, 8\n",
    "d = 10\n",
    "#T = 6\n",
    "model = ConvLSTMCell((h,w),c,d,(3,3),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = Variable(torch.rand(4, c, h, w))\n",
    "x2 = Variable(torch.rand(7, c, h, w))\n",
    "y1 = Variable(torch.randn(4, d, h, w))\n",
    "y2 = Variable(torch.randn(7, d, h, w))\n",
    "real = Variable(torch.from_numpy(np.array([1,0]).reshape(-1,1))).float()\n",
    "x = [x1,x2]\n",
    "y = [y1,y2]\n",
    "real[0].view(-1,1).size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 200000\n",
    "lr = 1.e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "for epoch in range(1, max_epoch+1):\n",
    "    \n",
    "    for k in range(len(x)):\n",
    "        inp = x[k]\n",
    "        #out = y[k]\n",
    "        state = None\n",
    "        #loss = 0\n",
    "        #print(inp.size(),out.size())\n",
    "        for t in range(0, inp.size()[0]):\n",
    "            state,sig_out = model.forward(inp[t:t+1,:,:,:],state)\n",
    "        \n",
    "        last_hidden = state[0]\n",
    "        last_sig = sig_out\n",
    "        #print(last_sig.size())\n",
    "        #sig = model.sig_out(last_hidden)\n",
    "        loss = loss_fn(last_sig, real[k].view(-1,1))\n",
    "        #print(last_sig,real[k])\n",
    "        if epoch %1000 == 0:\n",
    "            print(' > Epoch {:2d} loss: {:.5f}'.format((epoch), loss.data[0]))\n",
    "            #print(last_sig,real[k])\n",
    "    \n",
    "        model.zero_grad()\n",
    "\n",
    "    # compute new grad parameters through time!\n",
    "        loss.backward()\n",
    "\n",
    "    # learning_rate step against the gradient\n",
    "        \"\"\"for p in model.parameters():\n",
    "            p.data.sub_(p.grad.data * lr)\"\"\"\n",
    "        optimizer.step()\n",
    "            #print(p)\n",
    "    \n",
    "    #lr *= 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
