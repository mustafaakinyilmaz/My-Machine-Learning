{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import skimage as sk\n",
    "sk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pair_training_loss = 0.0\n",
    "            pair_training_corrects = 0.0\n",
    "            pairs = list(pairs)\n",
    "\n",
    "            label = 0\n",
    "            k = 0\n",
    "\n",
    "            for folder in pairs:\n",
    "                if folder is not None:            \n",
    "                    X,Y = create_sets(folder,label)\n",
    "                    if k == 0:\n",
    "                        X_train_batch = X.copy()\n",
    "                        Y_train_batch = Y.copy()\n",
    "                    else:\n",
    "                        X_train_batch = np.concatenate([X_train_batch,X],axis=0)\n",
    "                        Y_train_batch = np.concatenate([Y_train_batch,Y],axis=0)\n",
    "                    k += 1\n",
    "                    \n",
    "                label += 1\n",
    "            \n",
    "\n",
    "            print(X_train_batch.shape,Y_train_batch.shape)\n",
    "            num_samples = Y_train_batch.shape[0]\n",
    "            print(\"num_samples: \"+str(num_samples))\n",
    "            X_train_batch = normalize(X_train_batch)\n",
    "            sub_batches = create_batches(X_train_batch,Y_train_batch,batch_size)\n",
    "            for X_minibatch,Y_minibatch in sub_batches:\n",
    "                Y_minibatch = one_hot(Y_minibatch,num_classes)\n",
    "                X_minibatch, Y_minibatch = torch.from_numpy(X_minibatch.reshape(X_minibatch.shape[0],3,224,224)).to(device).float(), torch.from_numpy(Y_minibatch).to(device).float()\n",
    "                output = compute_output(X_minibatch,model)\n",
    "                loss,correct = evaluate(output,Y_minibatch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pair_training_loss += loss.item()\n",
    "                pair_training_corrects += correct\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"res = models.resnet34(pretrained=True)\n",
    "for param in res.parameters():\n",
    "        param.requires_grad = False\n",
    "p = 0\n",
    "for child in res.children():\n",
    "    print(child)\n",
    "    print(p)\n",
    "    if p >= 5:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    p+=1\n",
    "    \n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(CNN, self).__init__()\n",
    "        self.feature_extractor = *list(original_model.children())[:-1]\n",
    "        self.classifier = nn.Linear(in_features=512,out_features=99,bias=True)\n",
    "    def forward(x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "cnn = CNN(res)\n",
    "#cnn\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pair_lists(train_test_path):\n",
    "    \n",
    "    class_names = [names for names in glob.glob(train_test_path+\"/*\")]\n",
    "    #print(class_names)\n",
    "    \n",
    "    a = []\n",
    "    for names in class_names:\n",
    "        folder = []\n",
    "        for folders in glob.glob(names+\"/*\"):\n",
    "            folder.append(folders)\n",
    "        a.append(folder)\n",
    "        \n",
    "\n",
    "    paired_folders = itertools.zip_longest(*a)\n",
    "    \n",
    "    return list(paired_folders)\n",
    "\n",
    "pair_training = create_pair_lists(train_test_path= \"Frames/Train\")\n",
    "pair_test =  create_pair_lists(train_test_path= \"Frames/Test\")\n",
    "#print(list(pair[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_toarray(im):\n",
    "    array = plt.imread(im)\n",
    "    array = resize(array,(224,224,3),anti_aliasing=True)\n",
    "    return array\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sets(folder,label):\n",
    "    X_ = []\n",
    "    Y_ = []\n",
    "    frame_list = []\n",
    "    for frame in glob.glob(folder+\"/*.jpg\"):\n",
    "        im_array = im_toarray(frame)\n",
    "        X_.append(im_array)\n",
    "        Y_.append(label)\n",
    "        frame_list.append(frame)\n",
    "    \n",
    "    return np.array(X_),np.array(Y_).reshape(-1,1),frame_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(array, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[array.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    X_normalized = (X - mean)/std\n",
    "    return X_normalized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    model.fc = nn.Linear(in_features=512, out_features=99, bias=True)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    p = 0\n",
    "    for child in model.children():\n",
    "        #print(p)\n",
    "        if p >=3:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        p += 1\n",
    "    \n",
    "    return model\n",
    "\n",
    "class RESNET(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(RESNET, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(*list(original_model.children())[:-1])\n",
    "        self.classifier = nn.Sequential(*list(original_model.children())[-1:])\n",
    "    def forward(self,x):\n",
    "        (m,nc,nw,nh) = x.size()\n",
    "        x = self.feature_extractor(x).view(m,-1)\n",
    "        x = self.classifier(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "    \n",
    "\"\"\"def compute_output(X,model):\n",
    "    out = F.softmax(model.forward(X),dim=1)\n",
    "    return out\"\"\"\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = model()\n",
    "#model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "#params = sum([np.prod(p.size()) for p in model_parameters])       \n",
    "res = RESNET(model).to(device).float()\n",
    "#a = torch.randn(1,3,224,224).cuda().float()\n",
    "#res(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(X,Y,all_frame_list,batch_size,shuffle=True):\n",
    "    l = Y.shape[0]\n",
    "    index = np.random.permutation(l)\n",
    "    X = X[index,:,:,:]\n",
    "    Y = Y[index,:]\n",
    "    all_frame_list = np.array(all_frame_list)\n",
    "    all_frame_list = all_frame_list[index]\n",
    "    #print(len(Y))\n",
    "    for i in range(0,Y.shape[0],batch_size):\n",
    "        yield(X[i:i+batch_size,:,:,:],Y[i:i+batch_size,:],all_frame_list[i:i+batch_size])\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(frame_array,conv_features):\n",
    "    #print(conv_features.detach().cpu().numpy().shape)\n",
    "    #print(frame_array)\n",
    "    for k in range(len(frame_array)):\n",
    "        jpg_path = frame_array[k]\n",
    "        #print(jpg_path)\n",
    "        npy_path = jpg_path[:-3] + \"npy\"\n",
    "        #print(npy_path)\n",
    "        array = conv_features[k,:,:,:]\n",
    "        np.save(npy_path,array.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stuff(train_or_test,pairs,batch_size,num_classes,optimizer,model):\n",
    "\n",
    "        pair_loss = 0.0\n",
    "        pair_corrects = 0.0\n",
    "        pairs = list(pairs)\n",
    "        #print(pairs)\n",
    "        label = 0\n",
    "        k = 0\n",
    "        \n",
    "        all_frame_list = []\n",
    "        for folder in pairs:\n",
    "            if folder is not None:            \n",
    "                X,Y,frame_list = create_sets(folder,label)\n",
    "                all_frame_list.append(frame_list)\n",
    "                if k == 0:\n",
    "                    X_batch = X.copy()\n",
    "                    Y_batch = Y.copy()\n",
    "                else:\n",
    "                    X_batch = np.concatenate([X_batch,X],axis=0)\n",
    "                    Y_batch = np.concatenate([Y_batch,Y],axis=0)\n",
    "                k += 1\n",
    "                    \n",
    "            label += 1\n",
    "        all_frame_list  = [val for sublist in all_frame_list for val in sublist] \n",
    "        #print(len(all_frame_list))\n",
    "        print(X_batch.shape,Y_batch.shape)\n",
    "        num_samples = Y_batch.shape[0]\n",
    "        print(\"num_samples: \"+str(num_samples))\n",
    "        X_batch = normalize(X_batch)\n",
    "        sub_batches = create_batches(X_batch,Y_batch,all_frame_list,batch_size)\n",
    "        for X_minibatch,Y_minibatch,frame_minibatch in sub_batches:\n",
    "            \n",
    "            Y_minibatch = one_hot(Y_minibatch,num_classes)\n",
    "            X_minibatch, Y_minibatch = torch.from_numpy(X_minibatch.reshape(X_minibatch.shape[0],3,224,224)).to(device).float(), torch.from_numpy(Y_minibatch.reshape(-1,num_classes)).to(device).float()\n",
    "            conv_features = model.feature_extractor(X_minibatch)\n",
    "            #classifier = model.classifier(conv_features)\n",
    "            output = model(X_minibatch)\n",
    "            \n",
    "            loss,correct = evaluate(output,Y_minibatch)\n",
    "            if train_or_test == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            pair_loss += loss.item()\n",
    "            pair_corrects += correct\n",
    "            save_features(frame_minibatch,conv_features)\n",
    "        \n",
    "        return pair_loss,pair_corrects,num_samples,model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,nb_epoch,learning_rate,paired_training_list,paired_test_list,device,batch_size):\n",
    "    \n",
    "    optims = filter(lambda p: p.requires_grad,model.parameters())    \n",
    "    optimizer = torch.optim.Adam(optims,lr=learning_rate)\n",
    "    print(\"There are total number of %d pairs in training set\"%len(paired_training_list))\n",
    "    print(\"There are total number of %d pairs in test set\"%len(paired_test_list))\n",
    "    num_classes = 99\n",
    "    \n",
    "    for epoch in range(1,nb_epoch+1):\n",
    "\n",
    "        train_epoch_loss = 0.0\n",
    "        test_epoch_loss = 0.0\n",
    "        pair_nu = 1\n",
    "        for train_pairs in paired_training_list:\n",
    "            \n",
    "            pair_training_loss,pair_training_corrects,num_samples,model = train_stuff(\"train\",train_pairs,batch_size,num_classes,optimizer,model)\n",
    "            print(\"pair: \"+str(pair_nu))\n",
    "            print(\"pair training loss:\" +str(pair_training_loss))\n",
    "            print(\"pair training accuracy: \"+str(100*pair_training_corrects/num_samples))\n",
    "            pair_nu += 1\n",
    "            \"\"\"pair_test_loss,pair_test_corrects,num_samples,model = train_stuff(\"test\",test_pairs,batch_size,num_classes,optimizer,model)    \n",
    "            print(\"pair test loss:\" +str(pair_test_loss))\n",
    "            print(\"pair test accuracy: \"+str(100*pair_test_corrects/num_samples))\n",
    "            \n",
    "            train_epoch_loss += pair_training_loss\n",
    "            test_epoch_loss += pair_test_loss\"\"\"\n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "        print(\"epoch: \"+str(epoch))\n",
    "        print(\"epoch loss: \" +str(epoch_loss/num_classes))\n",
    "    \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(out,real):\n",
    "    #print(out.size(),real.size())\n",
    "    log_loss = torch.mean(-real*torch.log(out))\n",
    "    mean_loss = torch.mean((out-real)**2)\n",
    "    \n",
    "    loss = (mean_loss + log_loss)/2.0\n",
    "    \n",
    "    real_arg = torch.argmax(real,dim=1)\n",
    "    out_arg = torch.argmax(out,dim=1)\n",
    "    #print(sum(out_arg==real_arg).item())\n",
    "    correct = sum(out_arg==real_arg).item()\n",
    "    return log_loss,correct\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(res,2,1.e-3,pair_training,pair_test,device,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,1,1,2,3,3,3,4,5,5,5,5])\n",
    "b = np.array([1,0,0,2,4,3,5,5,4,4,5,1])\n",
    "\n",
    "a = torch.from_numpy(one_hot(a,7)).float()\n",
    "b = torch.from_numpy(one_hot(b,7)).float()\n",
    "\n",
    "loss,accuracy = evaluate(a,b)\n",
    "print(loss,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def call_data(selected_videos,class_path,label):\n",
    "    X, Y = [], []\n",
    "    #class_names = [names for names in glob.glob(path+\"/*\")]\n",
    "    \n",
    "    video_folders = [video for video in glob.glob(class_path+\"/*\")]\n",
    "    #print(video_folders)\n",
    "    shuffled_videos = list(np.random.permutation(video_folders))\n",
    "    unused_videos = list(set(shuffled_videos) - set(selected_videos))\n",
    "    if len(unused_videos) != 0:\n",
    "        selected_video = unused_videos[0]\n",
    "        selected_videos.append(selected_video)\n",
    "        \n",
    "        for frame in glob.glob(selected_video+\"/*.jpg\"):\n",
    "            im_array = im_toarray(frame)\n",
    "            X.append(im_array)\n",
    "            Y.append(label)\n",
    "    \n",
    "    return np.array(X),np.array(Y),selected_videos\"\"\"\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1,1,1,1,1,2,2,4,4,9,9,9])\n",
    "a = np.array([1,1,1,1,1,2,2,4,4,9,9,9])\n",
    "\n",
    "on = one_hot(b,10)\n",
    "#b_n = normalize(b)\n",
    "#b_n\n",
    "on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_t = torch.from_numpy(on)\n",
    "print(torch.argmax(on_t,dim=1).topk(5))\n",
    "arg = np.argmax(on,axis=1)\n",
    "#on_t = torch.from_numpy(on)\n",
    "#argt = torch.argmax(on_t,dim=1)\n",
    "#arg,arg_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [1,2,3,4,5]\n",
    "\n",
    "k = [[\"asd/frame1.jpg\"],[\"fgh/frame0.jpg\"]]\n",
    "j = np.random.permutation(4)\n",
    "k = np.array(k)\n",
    "jpg = k[0][0]\n",
    "jpg[:-3] + \"npy\"\n",
    "i[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
