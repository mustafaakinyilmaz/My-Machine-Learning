{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import skimage as sk\n",
    "sk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"res = models.resnet34(pretrained=True)\n",
    "for param in res.parameters():\n",
    "        param.requires_grad = False\n",
    "p = 0\n",
    "for child in res.children():\n",
    "    print(child)\n",
    "    print(p)\n",
    "    if p >= 5:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    p+=1\n",
    "    \n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(CNN, self).__init__()\n",
    "        self.feature_extractor = *list(original_model.children())[:-1]\n",
    "        self.classifier = nn.Linear(in_features=512,out_features=99,bias=True)\n",
    "    def forward(x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "cnn = CNN(res)\n",
    "#cnn\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_pair_lists(train_test_path):\n",
    "    \n",
    "    class_names = [names for names in glob.glob(train_test_path+\"/*\")]\n",
    "    #print(class_names)\n",
    "    \n",
    "    a = []\n",
    "    for names in class_names:\n",
    "        folder = []\n",
    "        for folders in glob.glob(names+\"/*\"):\n",
    "            folder.append(folders)\n",
    "        a.append(folder)\n",
    "        \n",
    "\n",
    "    paired_folders = itertools.zip_longest(*a)\n",
    "    \n",
    "    return list(paired_folders)\n",
    "\n",
    "pair = create_pair_lists(train_test_path= \"Frames/Train\")\n",
    "type(pair) \n",
    "#print(list(pair[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_toarray(im):\n",
    "    array = plt.imread(im)\n",
    "    array = resize(array,(224,224,3),anti_aliasing=True)\n",
    "    return array\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sets(folder,label):\n",
    "    X_ = []\n",
    "    Y_ = []\n",
    "    for frame in glob.glob(folder+\"/*.jpg\"):\n",
    "        im_array = im_toarray(frame)\n",
    "        X_.append(im_array)\n",
    "        Y_.append(label)\n",
    "    \n",
    "    return np.array(X_),np.array(Y_).reshape(-1,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(array, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[array.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    X_normalized = (X - mean)/std\n",
    "    return X_normalized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "\n",
    "    model = models.resnet18(pretrained=True)\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"model.classifier = nn.Sequential(nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(p=0.5),\n",
    "                                     nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(p=0.5),\n",
    "                                     nn.Linear(in_features=4096, out_features=99, bias=True))\"\"\"\n",
    "    model.fc = nn.Linear(in_features=512, out_features=99, bias=True)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    p = 0\n",
    "    for child in model.children():\n",
    "\n",
    "        if p >=4:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        p += 1\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compute_output(X,model):\n",
    "    out = F.softmax(model.forward(X),dim=1)\n",
    "    return out\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = model().to(device).float()\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "#params = sum([np.prod(p.size()) for p in model_parameters])       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(X,Y,batch_size,shuffle=True):\n",
    "    l = len(Y)\n",
    "    index = np.random.permutation(l)\n",
    "    X = X[index,:,:,:]\n",
    "    Y = Y[index,:]\n",
    "    #print(len(Y))\n",
    "    for i in range(0,Y.shape[0],batch_size):\n",
    "        yield(X[i:i+batch_size,:,:,:],Y[i:i+batch_size,:])\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,nb_epoch,learning_rate,paired_training_list,device,batch_size):\n",
    "    \n",
    "    optims = filter(lambda p: p.requires_grad,model.parameters())    \n",
    "    optimizer = torch.optim.Adam(optims,lr=learning_rate)\n",
    "    #print(sum([np.prod(p.size()) for p in optims]))  \n",
    "    num_classes = 99\n",
    "    for epoch in range(1,nb_epoch+1):\n",
    "        epoch_loss = 0.0\n",
    "        for pairs in paired_training_list:\n",
    "            pair_loss = 0.0\n",
    "            pair_corrects = 0.0\n",
    "            pairs = list(pairs)\n",
    "\n",
    "            label = 0\n",
    "            k = 0\n",
    "\n",
    "            for folder in pairs:\n",
    "                if folder is not None:            \n",
    "                    X,Y = create_sets(folder,label)\n",
    "                    if k == 0:\n",
    "                        #print(folder)\n",
    "                        #print(\"here\")\n",
    "                        X_train_batch = X.copy()\n",
    "                        Y_train_batch = Y.copy()\n",
    "                    else:\n",
    "                        X_train_batch = np.concatenate([X_train_batch,X],axis=0)\n",
    "                        Y_train_batch = np.concatenate([Y_train_batch,Y],axis=0)\n",
    "                    k += 1\n",
    "                    \n",
    "                label += 1\n",
    "            \n",
    "\n",
    "            print(X_train_batch.shape,Y_train_batch.shape)\n",
    "            num_samples = Y_train_batch.shape[0]\n",
    "            print(\"num_samples: \"+str(num_samples))\n",
    "            X_train_batch = normalize(X_train_batch)\n",
    "            sub_batches = create_batches(X_train_batch,Y_train_batch,batch_size)\n",
    "            for X_minibatch,Y_minibatch in sub_batches:\n",
    "                Y_minibatch = one_hot(Y_minibatch,num_classes)\n",
    "                X_minibatch, Y_minibatch = torch.from_numpy(X_minibatch.reshape(X_minibatch.shape[0],3,224,224)).to(device).float(), torch.from_numpy(Y_minibatch).to(device).float()\n",
    "                output = compute_output(X_minibatch,model)\n",
    "                loss,correct = evaluate(output,Y_minibatch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pair_loss += loss.item()\n",
    "                pair_corrects += correct\n",
    "            \n",
    "            epoch_loss += pair_loss\n",
    "            print(\"pair loss:\" +str(pair_loss))\n",
    "            print(\"pair accuracy: \"+str(100*pair_corrects/num_samples))\n",
    "            \n",
    "        print(\"epoch: \"+str(epoch))\n",
    "        print(\"epoch loss: \" +str(epoch_loss/num_classes))\n",
    "    \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(out,real):\n",
    "    log_loss = torch.mean(-real*torch.log(out))\n",
    "    mean_loss = torch.mean((out-real)**2)\n",
    "    \n",
    "    loss = (mean_loss + log_loss)/2.0\n",
    "    \n",
    "    num_of_samples = real.size()[0]\n",
    "    real_arg = torch.argmax(real,dim=1)\n",
    "    out_arg = torch.argmax(out,dim=1)\n",
    "    #print(real_arg,out_arg)\n",
    "    #print(sum(out_arg==real_arg).item())\n",
    "    correct = sum(out_arg==real_arg).item()\n",
    "    return log_loss,correct\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(749, 224, 224, 3) (749, 1)\n",
      "num_samples: 749\n",
      "pair loss:0.32630000123754144\n",
      "pair accuracy: 69.02536715620828\n",
      "(730, 224, 224, 3) (730, 1)\n",
      "num_samples: 730\n",
      "pair loss:0.2714096244890243\n",
      "pair accuracy: 70.68493150684931\n",
      "(778, 224, 224, 3) (778, 1)\n",
      "num_samples: 778\n",
      "pair loss:0.17417144868522882\n",
      "pair accuracy: 83.16195372750643\n",
      "(778, 224, 224, 3) (778, 1)\n",
      "num_samples: 778\n",
      "pair loss:0.1269367238273844\n",
      "pair accuracy: 86.63239074550128\n"
     ]
    }
   ],
   "source": [
    "train_model(model,2,1.e-3,pair,device,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,1,1,2,3,3,3,4,5,5,5,5])\n",
    "b = np.array([1,0,0,2,4,3,5,5,4,4,5,1])\n",
    "\n",
    "a = torch.from_numpy(one_hot(a,7)).float()\n",
    "b = torch.from_numpy(one_hot(b,7)).float()\n",
    "\n",
    "loss,accuracy = evaluate(a,b)\n",
    "print(loss,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def call_data(selected_videos,class_path,label):\n",
    "    X, Y = [], []\n",
    "    #class_names = [names for names in glob.glob(path+\"/*\")]\n",
    "    \n",
    "    video_folders = [video for video in glob.glob(class_path+\"/*\")]\n",
    "    #print(video_folders)\n",
    "    shuffled_videos = list(np.random.permutation(video_folders))\n",
    "    unused_videos = list(set(shuffled_videos) - set(selected_videos))\n",
    "    if len(unused_videos) != 0:\n",
    "        selected_video = unused_videos[0]\n",
    "        selected_videos.append(selected_video)\n",
    "        \n",
    "        for frame in glob.glob(selected_video+\"/*.jpg\"):\n",
    "            im_array = im_toarray(frame)\n",
    "            X.append(im_array)\n",
    "            Y.append(label)\n",
    "    \n",
    "    return np.array(X),np.array(Y),selected_videos\"\"\"\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1,1,1,1,1,2,2,4,4,9,9,9])\n",
    "a = np.array([1,1,1,1,1,2,2,4,4,9,9,9])\n",
    "\n",
    "on = one_hot(b,10)\n",
    "#b_n = normalize(b)\n",
    "#b_n\n",
    "on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_t = torch.from_numpy(on)\n",
    "print(torch.argmax(on_t,dim=1).topk(5))\n",
    "arg = np.argmax(on,axis=1)\n",
    "#on_t = torch.from_numpy(on)\n",
    "#argt = torch.argmax(on_t,dim=1)\n",
    "#arg,arg_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
