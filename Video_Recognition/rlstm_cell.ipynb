{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import skimage as sk\n",
    "from natsort import natsorted\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_tensor(array):\n",
    "    tensor = torch.from_numpy(array)\n",
    "    return tensor\n",
    "\n",
    "def normalize(X):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    X_normalized = (X - mean)/std\n",
    "    return X_normalized\n",
    "\n",
    "\n",
    "def one_hot(array, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[array.reshape(-1)])\n",
    "\n",
    "def im_toarray(im):\n",
    "    array = plt.imread(im)\n",
    "    array = resize(array,(224,224,3),anti_aliasing=True)\n",
    "    return array\n",
    "\n",
    "def create_sets(folder,label):\n",
    "    X_ = []\n",
    "    Y_ = []\n",
    "\n",
    "\n",
    "    for frame in glob.glob(folder+\"/*.jpg\"):\n",
    "        im_array = im_toarray(frame)\n",
    "        X_.append(im_array)\n",
    "        Y_.append(label)\n",
    "\n",
    "    \n",
    "    return normalize(np.array(X_)),np.array(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, kernel_size, stride, padding, bias, use_max):\n",
    "        super(Conv, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.bias = bias\n",
    "        self.use_max = use_max\n",
    "        \n",
    "        self.conv2d = nn.Conv2d(in_channels=input_dim,\n",
    "                              out_channels=out_dim,\n",
    "                              kernel_size=kernel_size,\n",
    "                              stride=stride,\n",
    "                              padding=padding,\n",
    "                              bias=bias)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=kernel_size//2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv2d(x)\n",
    "        if self.use_max:\n",
    "            out = self.maxpool(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, kernel_size, bias):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.batch,self.input_channel,self.height, self.width = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias        = bias\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=self.input_channel + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "        \n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        \n",
    "        if cur_state is None:\n",
    "            cur_state = (Variable(torch.zeros(1, self.hidden_dim, self.height, self.width)),\n",
    "                Variable(torch.zeros(1, self.hidden_dim, self.height, self.width)))\n",
    "        \n",
    "        h_cur, c_cur = cur_state\n",
    "        combined = torch.cat((input_tensor, h_cur), dim=1)  # concatenate along channel axis\n",
    "        #print(combined.size())\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1) \n",
    "\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        \n",
    "        next_state = (h_next,c_next)\n",
    "        return next_state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stack, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.conv1 = Conv(3,128,5,1,0,True,True)\n",
    "        self.convlstm1 = ConvLSTMCell((1,128,110,110),256,(3,3),True)\n",
    "        self.conv2 = Conv(256,256,4,1,0,True,True)\n",
    "        self.convlstm2 = ConvLSTMCell((1,256,53,53),512,(3,3),True)\n",
    "        self.conv3 = Conv(512,1024,5,5,0,True,True)\n",
    "        self.linear = nn.Linear(1024*5*5,99,bias=True)\n",
    "        \n",
    "    def forward(self,x,state1,state2):\n",
    "        \n",
    "        conv1_o = self.conv1(x)\n",
    "        convlstm_h1,convlstm_c1 = self.convlstm1(conv1_o,state1)\n",
    "        conv2_o = self.conv2(convlstm_h1)\n",
    "        convlstm_h2,convlstm_c2 = self.convlstm2(conv2_o,state2)\n",
    "        conv3_o = self.conv3(convlstm_h2)\n",
    "        flatten = conv3_o.view(1,-1)\n",
    "        soft = F.softmax(self.linear(flatten),dim=1)\n",
    "        \n",
    "        state2 = (convlstm_h2,convlstm_c2)\n",
    "        state1 = (convlstm_h1,convlstm_c1)\n",
    "        \n",
    "        return soft,state2,state1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1,3,224,224)\n",
    "s_model = Stack()\n",
    "o,d,f = s_model(a,None,None)\n",
    "o.size()\n",
    "model_parameters = filter(lambda p: p.requires_grad, s_model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])  \n",
    "print(params)\n",
    "o.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(out,real):\n",
    "\n",
    "    log_loss = torch.mean(-real*torch.log(out))\n",
    "    mean_loss = torch.mean((out-real)**2)\n",
    "    \n",
    "    loss = (mean_loss + log_loss)/2.0\n",
    "\n",
    "    return log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder1 = \"Frames/Train/ApplyLipstick/1\"\n",
    "X1,Y1 = create_sets(folder1,78)\n",
    "X1 = X1.reshape(-1,3,224,224)\n",
    "Y1 = one_hot(Y1,99)\n",
    "X1,Y1 = array_to_tensor(X1).to(device).float(),array_to_tensor(Y1).to(device).float()\n",
    "\n",
    "folder2 = \"Frames/Train/Bowling/1\"\n",
    "X2,Y2 = create_sets(folder2,55)\n",
    "X2 = X2.reshape(-1,3,224,224)\n",
    "Y2 = one_hot(Y2,99)\n",
    "X2,Y2 = array_to_tensor(X2).to(device).float(),array_to_tensor(Y2).to(device).float()\n",
    "\n",
    "xlist = [X1]\n",
    "ylist = [Y1]\n",
    "\n",
    "optimizer = torch.optim.SGD(s_model.parameters(),lr=1.e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(500):\n",
    "    for k in range(len(xlist)):\n",
    "        inp = xlist[k]\n",
    "        real = ylist[k]\n",
    "        state1 = None\n",
    "        state2 = None\n",
    "        pair_loss = 0\n",
    "        for i in range(inp.size(0)):\n",
    "            out,state2,state1 = s_model(inp[i:i+1],state1,state2)\n",
    "            loss = calculate_loss(out,real[i:i+1])\n",
    "            pair_loss += loss\n",
    "        \n",
    "        pair_loss_av = pair_loss/i\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pair_loss_av.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(pair_loss_av.item())\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
