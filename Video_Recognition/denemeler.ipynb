{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import skimage as sk\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1,10)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = F.softmax(a,dim=1)\n",
    "b,b.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,8,9,11]\n",
    "b = [4,5,6,10]\n",
    "\n",
    "la = len(a)\n",
    "lb = len(b)\n",
    "\n",
    "max_ = max(la,lb)\n",
    "for k in range(max_):\n",
    "    pair_train = a[k]\n",
    "    pair_test = b[k%lb]\n",
    "    print(pair_train,pair_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model__ = torch.load(\"cnn_extract_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1,3,224,224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model__[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model():\n",
    "\n",
    "    model = models.resnet34(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    p = 0\n",
    "    for child in model.children():\n",
    "        if p >= 6:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        p += 1\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class RESNET(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(RESNET, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(*list(original_model.children())[:-1])\n",
    "        self.fc1 = nn.Linear(in_features=512,out_features=99,bias=True)\n",
    "        #self.fc2 = nn.Linear(in_features=512,out_features=99,bias=True)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        (m,nc,nw,nh) = x.size()\n",
    "        cnn = self.feature_extractor(x).view(m,-1)\n",
    "        fc1 = self.fc1(cnn)\n",
    "        #relu1 = F.relu(fc1)\n",
    "        drop1 = self.dropout(fc1)\n",
    "        #fc2 = self.fc2(drop1)\n",
    "        out = F.log_softmax(drop1,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model()\n",
    "res = RESNET(m)\n",
    "\n",
    "res.load_state_dict(torch.load(\"cnn_extract_model.pth\")[\"state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"Frames/Train/\"\n",
    "\n",
    "def data_loader(path,batch_size,shuffle):\n",
    "    all_img_list = []\n",
    "    all_class_list = []\n",
    "    \n",
    "    train_list = glob.glob(path+\"*\")\n",
    "    \n",
    "    class_no = 0\n",
    "    for classes in train_list:\n",
    "        class_list = glob.glob(classes+\"/*\")\n",
    "        for folders in class_list:\n",
    "            img_list = glob.glob(folders+\"/*.jpg\")\n",
    "            for images in img_list:\n",
    "                all_img_list.append(images)\n",
    "                all_class_list.append(class_no)\n",
    "        \n",
    "        class_no += 1\n",
    "    \n",
    "    index = np.random.permutation(len(all_img_list))\n",
    "    random_img = np.array(all_img_list)[index]\n",
    "    random_class = np.array(all_class_list)[index]\n",
    "    \n",
    "    for i in range(0,len(all_img_list),batch_size):\n",
    "        yield(random_img[i:i+batch_size],random_class[i:i+batch_size])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3, 224, 224) [66 59 48 55 13 16 72 91 74 75 40 74 34 97 75 94]\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(im_list,cls_list):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for im,cl in zip(im_list,cls_list):\n",
    "        image = Image.open(im)\n",
    "        im_array = preprocess(image).numpy()\n",
    "        X.append(im_array)\n",
    "        Y.append(cl)\n",
    "    return np.array(X),np.array(Y)\n",
    "        \n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Scale(256),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "\n",
    "sub_batches = data_loader(train,16,True)\n",
    "for imgs,clls in sub_batches:\n",
    "    X,Y = prepare_data(imgs,clls)\n",
    "    print(X.shape,Y)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.permutation(4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([\"a\",\"b\",5,6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', 'b', 'a', '6'], \n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 4\n",
      "as 5\n",
      "df 6\n"
     ]
    }
   ],
   "source": [
    "a = [\"k\",\"as\",\"df\"]\n",
    "b = [4,5,6]\n",
    "for i,j in zip(a,b):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
