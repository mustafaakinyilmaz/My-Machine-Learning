{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import skimage as sk\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "logging.basicConfig(filename='cnn_extract.log',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Scale(256),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pairs,batch_size,num_classes,model):\n",
    "    pair_loss = 0.0\n",
    "    pair_corrects = 0\n",
    "    pairs = list(pairs)\n",
    "    label = 0\n",
    "    k = 0\n",
    "\n",
    "    all_frame_list = []\n",
    "    for folder in pairs:\n",
    "        if folder is not None:\n",
    "            X,Y,frame_list = create_sets(folder,label)\n",
    "            all_frame_list.append(frame_list)\n",
    "            if k == 0:\n",
    "                X_batch = X.copy()\n",
    "                Y_batch = Y.copy()\n",
    "            else:\n",
    "                X_batch = np.concatenate([X_batch,X],axis=0)\n",
    "                Y_batch = np.concatenate([Y_batch,Y],axis=0)\n",
    "            k += 1\n",
    "\n",
    "        label += 1\n",
    "    all_frame_list  = [val for sublist in all_frame_list for val in sublist]\n",
    "\n",
    "\n",
    "    num_samples = Y_batch.shape[0]\n",
    "    sub_batches = create_batches(X_batch,Y_batch,all_frame_list,batch_size)\n",
    "    for X_minibatch,Y_minibatch,frame_minibatch in sub_batches:\n",
    "\n",
    "        Y_minibatch = one_hot(Y_minibatch,num_classes)\n",
    "        X_minibatch, Y_minibatch = torch.from_numpy(X_minibatch).to(device).float(), torch.from_numpy(Y_minibatch.reshape(-1,num_classes)).to(device).float()\n",
    "        output = model(X_minibatch)\n",
    "\n",
    "        loss,correct = evaluate(output,Y_minibatch)\n",
    "            \n",
    "        pair_loss += loss.item()\n",
    "        pair_corrects += correct\n",
    "        #save_features(frame_minibatch,output)\n",
    "\n",
    "    return pair_loss,pair_corrects,num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model():\n",
    "\n",
    "    model = models.resnet34(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    p = 0\n",
    "    for child in model.children():\n",
    "        if p >= 6:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        p += 1\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class RESNET(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(RESNET, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(*list(original_model.children())[:-1])\n",
    "        self.fc1 = nn.Linear(in_features=512,out_features=99,bias=True)\n",
    "        #self.fc2 = nn.Linear(in_features=512,out_features=99,bias=True)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        (m,nc,nw,nh) = x.size()\n",
    "        cnn = self.feature_extractor(x).view(m,-1)\n",
    "        fc1 = self.fc1(cnn)\n",
    "        #relu1 = F.relu(fc1)\n",
    "        drop1 = self.dropout(fc1)\n",
    "        #fc2 = self.fc2(drop1)\n",
    "        out = F.log_softmax(drop1,dim=1)\n",
    "        return out\n",
    "\n",
    "def create_batches(X,Y,all_frame_list,batch_size,shuffle=True):\n",
    "    l = Y.shape[0]\n",
    "    index = np.random.permutation(l)\n",
    "    X = X[index,:,:,:]\n",
    "    Y = Y[index,:]\n",
    "    all_frame_list = np.array(all_frame_list)\n",
    "    all_frame_list = all_frame_list[index]\n",
    "    #print(len(Y))\n",
    "    for i in range(0,Y.shape[0],batch_size):\n",
    "        yield(X[i:i+batch_size,:,:,:],Y[i:i+batch_size,:],all_frame_list[i:i+batch_size])\n",
    "\n",
    "\n",
    "def save_features(frame_array,conv_features):\n",
    "    for k in range(len(frame_array)):\n",
    "        jpg_path = frame_array[k]\n",
    "        npy_path = jpg_path[:-3] + \"npy\"\n",
    "        array = conv_features[k]\n",
    "        #np.save(npy_path,array.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model,nb_epoch,learning_rate,paired_training_list,paired_test_list,device,batch_size):\n",
    "\n",
    "    optims = filter(lambda p: p.requires_grad,model.parameters())\n",
    "    optimizer = torch.optim.Adam(optims,lr=learning_rate)\n",
    "    logging.info(\"There are total number of %d pairs in training set\"%len(paired_training_list))\n",
    "    logging.info(\"There are total number of %d pairs in test set\"%len(paired_test_list))\n",
    "    num_classes = 99\n",
    "\n",
    "    for epoch in range(1,nb_epoch+1):\n",
    "\n",
    "        train_epoch_loss = 0.0\n",
    "        train_epoch_correct = 0\n",
    "        \n",
    "        test_epoch_loss = 0.0\n",
    "        test_epoch_correct = 0\n",
    "        \n",
    "        pair_nu = 1\n",
    "        \n",
    "        train_total_image = 0\n",
    "        test_total_image = 0\n",
    "        \n",
    "        len_train = len(paired_training_list)\n",
    "        len_test = len(paired_test_list)\n",
    "    \n",
    "        \n",
    "        \n",
    "        for k in range(len_train):\n",
    "            train_pairs = paired_training_list[k]\n",
    "            test_pairs = paired_test_list[k%len_test]\n",
    "            \n",
    "            pair_training_loss,pair_training_corrects,train_num_samples = train(train_pairs,batch_size,num_classes,optimizer,model)\n",
    "            logging.info(\"pair: \"+str(pair_nu))\n",
    "            logging.info(\"pair training loss:\" +str(pair_training_loss/train_num_samples))\n",
    "            logging.info(\"pair training accuracy: \"+str(100*pair_training_corrects/train_num_samples)+\" \"+str(pair_training_corrects)+\"/\"+str(train_num_samples))\n",
    "            logging.info(\"********\")\n",
    "            pair_nu += 1\n",
    "            train_epoch_loss += pair_training_loss\n",
    "            train_epoch_correct += pair_training_corrects\n",
    "            train_total_image += train_num_samples\n",
    "            \n",
    "            \n",
    "            pair_test_loss,pair_test_corrects,test_num_samples = test(test_pairs,batch_size,num_classes,model)\n",
    "            logging.info(\"pair test loss:\" +str(pair_test_loss/test_num_samples))\n",
    "            logging.info(\"pair test accuracy: \"+str(100*pair_test_corrects/test_num_samples)+\" \"+str(pair_test_corrects)+\"/\"+str(test_num_samples))\n",
    "            logging.info(\"********\")\n",
    "            test_epoch_loss += pair_test_loss\n",
    "            test_epoch_correct += pair_test_corrects\n",
    "            test_total_image += test_num_samples\n",
    "\n",
    "\n",
    "        logging.info(\"epoch: \"+str(epoch))\n",
    "        logging.info(\"epoch training loss: \" +str(train_epoch_loss/train_total_image))\n",
    "        logging.info(\"epoch training accuracy: \"+str(100*train_epoch_correct/train_total_image)+\" \"+str(train_epoch_correct)+\"/\"+str(train_total_image))\n",
    "        logging.info(\"epoch test loss: \" +str(test_epoch_loss/test_total_image))\n",
    "        logging.info(\"epoch test accuracy: \"+str(100*test_epoch_correct/test_total_image)+\" \"+str(test_epoch_correct)+\"/\"+str(test_total_image))\n",
    "        logging.info(\"-----------------\")\n",
    "        logging.info(\"-----------------\")\n",
    "        \n",
    "        save_model(epoch,model,optimizer)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def evaluate(out,real):\n",
    "    #print(out.size(),real.size())\n",
    "    log_loss = torch.sum(-real*out)\n",
    "    mean_loss = torch.sum((out-real)**2)\n",
    "\n",
    "    loss = (mean_loss + log_loss)/2.0\n",
    "\n",
    "    real_arg = torch.argmax(real,dim=1)\n",
    "    out_arg = torch.argmax(out,dim=1)\n",
    "    #print(sum(out_arg==real_arg).item())\n",
    "    correct = sum(out_arg==real_arg).item()\n",
    "    return log_loss,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(pairs,batch_size,num_classes,optimizer,model):\n",
    "\n",
    "        pair_loss = 0.0\n",
    "        pair_corrects = 0\n",
    "        pairs = list(pairs)\n",
    "        label = 0\n",
    "        k = 0\n",
    "\n",
    "        all_frame_list = []\n",
    "        for folder in pairs:\n",
    "            if folder is not None:\n",
    "                X,Y,frame_list = create_sets(folder,label)\n",
    "                all_frame_list.append(frame_list)\n",
    "                if k == 0:\n",
    "                    X_batch = X.copy()\n",
    "                    Y_batch = Y.copy()\n",
    "                else:\n",
    "                    X_batch = np.concatenate([X_batch,X],axis=0)\n",
    "                    Y_batch = np.concatenate([Y_batch,Y],axis=0)\n",
    "                k += 1\n",
    "\n",
    "            label += 1\n",
    "        all_frame_list  = [val for sublist in all_frame_list for val in sublist]\n",
    "\n",
    "\n",
    "        num_samples = Y_batch.shape[0]\n",
    "        sub_batches = create_batches(X_batch,Y_batch,all_frame_list,batch_size)\n",
    "        for X_minibatch,Y_minibatch,frame_minibatch in sub_batches:\n",
    "\n",
    "            Y_minibatch = one_hot(Y_minibatch,num_classes)\n",
    "            X_minibatch, Y_minibatch = torch.from_numpy(X_minibatch).to(device).float(), torch.from_numpy(Y_minibatch.reshape(-1,num_classes)).to(device).float()\n",
    "            output = model(X_minibatch)\n",
    "            #print(output.size(),Y_minibatch.size())\n",
    "\n",
    "            loss,correct = evaluate(output,Y_minibatch)\n",
    "            \n",
    "            av_loss = loss/Y_minibatch.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            av_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            pair_loss += loss.item()\n",
    "            pair_corrects += correct\n",
    "            #save_features(frame_minibatch,output)\n",
    "\n",
    "        return pair_loss,pair_corrects,num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pair_lists(train_test_path):\n",
    "\n",
    "    class_names = [names for names in glob.glob(train_test_path+\"/*\")]\n",
    "    #print(class_names)\n",
    "\n",
    "    a = []\n",
    "    for names in class_names:\n",
    "        folder = []\n",
    "        for folders in glob.glob(names+\"/*\"):\n",
    "            folder.append(folders)\n",
    "        a.append(folder)\n",
    "\n",
    "\n",
    "    paired_folders = itertools.zip_longest(*a)\n",
    "\n",
    "    return list(paired_folders)\n",
    "\n",
    "def im_toarray(im):\n",
    "    image = Image.open(im)\n",
    "    im_array = preprocess(image).numpy()\n",
    "    return im_array\n",
    "\n",
    "def create_sets(folder,label):\n",
    "    X_ = []\n",
    "    Y_ = []\n",
    "    frame_list = []\n",
    "    for frame in glob.glob(folder+\"/*.jpg\"):\n",
    "        im_array = im_toarray(frame)\n",
    "        X_.append(im_array)\n",
    "        Y_.append(label)\n",
    "        frame_list.append(frame)\n",
    "\n",
    "    return np.array(X_),np.array(Y_).reshape(-1,1),frame_list\n",
    "\n",
    "\n",
    "def one_hot(array, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[array.reshape(-1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch,model,optimizer):\n",
    "    state = {\n",
    "    'epoch': epoch,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, \"cnn_extract_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_training = create_pair_lists(train_test_path= \"Frames/Train\")\n",
    "pair_test = create_pair_lists(train_test_path= \"Frames/Test\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = model()\n",
    "resnet = RESNET(model).to(device).float()\n",
    "\n",
    "\n",
    "\n",
    "train_model(resnet,25,1.e-2,pair_training,pair_test,device,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
