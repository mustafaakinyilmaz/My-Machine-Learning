{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import skimage as sk\n",
    "from natsort import natsorted\n",
    "#torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self,class_size, input_size, input_dim, hidden_dim, kernel_size, bias):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "    \n",
    "        self.height, self.width = input_size\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias        = bias\n",
    "        self.class_size = class_size\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "        \n",
    "        self.linear = nn.Linear(in_features=self.hidden_dim*self.height*self.width,out_features=self.class_size,bias=self.bias)\n",
    "        \n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        \n",
    "        if cur_state is None:\n",
    "            cur_state = (Variable(torch.zeros(1, self.hidden_dim, self.height, self.width)),\n",
    "                Variable(torch.zeros(1, self.hidden_dim, self.height, self.width)))\n",
    "        \n",
    "        h_cur, c_cur = cur_state\n",
    "        \n",
    "        #print(input_tensor.size(),h_cur.size())\n",
    "        combined = torch.cat((input_tensor, h_cur), dim=1)  # concatenate along channel axis\n",
    "        #print(combined.size())\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1) \n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        \n",
    "        next_state = (h_next,c_next)\n",
    "        \n",
    "        softmax_out = F.softmax(self.linear(h_next.view(1,-1)),dim=1)\n",
    "        \n",
    "        return next_state,softmax_out\n",
    "\n",
    "conv_lstm_cell = ConvLSTMCell(99,(1,1),512,128,(3,3),True).float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pair_lists(train_test_path):\n",
    "    \n",
    "    class_names = [names for names in glob.glob(train_test_path+\"/*\")]\n",
    "    #print(class_names)\n",
    "    \n",
    "    a = []\n",
    "    for names in class_names:\n",
    "        folder = []\n",
    "        for folders in glob.glob(names+\"/*\"):\n",
    "            folder.append(folders)\n",
    "        a.append(folder)\n",
    "        \n",
    "\n",
    "    paired_folders = itertools.zip_longest(*a)\n",
    "    \n",
    "    return list(paired_folders)\n",
    "\n",
    "pair_training = create_pair_lists(train_test_path= \"Frames/Train\")\n",
    "#pair_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npy_list(folder):\n",
    "    npy_list = []\n",
    "    for npy_file in glob.glob(folder+\"/*.npy\"):\n",
    "        npy_list.append(npy_file)\n",
    "    npy_list = natsorted(npy_list)\n",
    "    \n",
    "    return npy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(array, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[array.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_npy(npy_list):\n",
    "    X = []\n",
    "    for npys in npy_list:\n",
    "        array = np.load(npys)\n",
    "        X.append(array)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_tensor(array):\n",
    "    tensor = torch.from_numpy(array).float()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(out,real):\n",
    "    #print(out.size())\n",
    "    #print(real.size())\n",
    "    #print(out.size(),real.size())\n",
    "    log_loss = torch.mean(-real*torch.log(out))\n",
    "    mean_loss = torch.mean((out-real)**2)\n",
    "    \n",
    "    loss = (mean_loss + log_loss)/2.0\n",
    "    \n",
    "    real_arg = torch.argmax(real,dim=1)\n",
    "    out_arg = torch.argmax(out,dim=1)\n",
    "    #print(sum(out_arg==real_arg).item())\n",
    "    correct = sum(out_arg==real_arg).item()\n",
    "    return log_loss,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy = npy_list(pair_training[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(nb_epoch,model,lr):\n",
    "    \n",
    "    optimizer = torch.optim.RMSprop(model.parameters(),lr=lr)\n",
    "    \n",
    "    nb_classes = 99\n",
    "    for epoch in range(1,nb_epoch+1):\n",
    "\n",
    "        train_epoch_loss = 0.0\n",
    "        test_epoch_loss = 0.0\n",
    "        pair_nu = 1\n",
    "\n",
    "        for train_pairs in pair_training:\n",
    "            \n",
    "            label = np.array([0])\n",
    "            for folders in train_pairs:            \n",
    "                print(folders)\n",
    "                Y = array_to_tensor(one_hot(label,nb_classes)).view(1,-1)\n",
    "        \n",
    "                if folders is not None:\n",
    "                \n",
    "                    np_list = npy_list(folders)\n",
    "                    X = concatenate_npy(np_list)\n",
    "                    X = array_to_tensor(X)\n",
    "\n",
    "                    state = None\n",
    "                    for f in range(0,X.size()[0]):\n",
    "                        inp = X[f:f+1]\n",
    "                        state,softmax_out = conv_lstm_cell(inp,state)\n",
    "                        #print(inp.size(),state[0].size(),softmax_out.size())\n",
    "\n",
    "                    last_hidden = state[0]\n",
    "                    last_softmax = softmax_out\n",
    "                    \n",
    "                    loss,correct = evaluate(last_softmax,Y)\n",
    "                    \n",
    "                    print(\"loss: \"+str(loss.item()))\n",
    "                    print(torch.argmax(last_softmax,dim=1).item())\n",
    "                    print(torch.argmax(Y,dim=1).item())\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                print(\"--------------\")\n",
    "                \n",
    "                label += 1\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm(1,conv_lstm_cell,1.e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,3,2,0])\n",
    "r = np.array([[0.2,0.3,0.4,0.1],[0.05,0.25,0.1,0.7],[0.3,0.35,0.2,0.15],[0.9,0.05,0.01,0.04]])\n",
    "on = one_hot(a,4)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(on,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(r.shape[0]):\n",
    "    row = r[e,:]\n",
    "    idx = (-row).argsort()[:2]\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = [0]\n",
    "k = np.array(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array([0])\n",
    "for k in range(5):\n",
    "    print(one_hot(label,5))\n",
    "    label += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
